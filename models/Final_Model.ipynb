{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the file locations to be used later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "No GPU detected, using CPU\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Check for GPU availability\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "if len(tf.config.experimental.list_physical_devices('GPU')) > 0:\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    print(\"No GPU detected, using CPU\")\n",
    "\n",
    "# Set paths for the data\n",
    "syspath = \"/kaggle/input/cvproject/\" # you need to replace in your syspath here\n",
    "image_dir = f'{syspath}stack-stability-prediction/src/data/train/'  # Path to the folder containing the images\n",
    "csv_path = syspath + \"/train.csv\"  # Path to the CSV file containing labels\n",
    "\n",
    "# Load the CSV file with image ids and labels\n",
    "data = pd.read_csv(csv_path)\n",
    "data['id'] = data['id'].astype(str) + '.jpg'\n",
    "data['stable_height'] -= 1\n",
    "\n",
    "# Ensure labels are integers and within the correct range\n",
    "data['stable_height'] = data['stable_height'].astype(int)  # Ensure labels are integers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code tries 3 different data augmentation scales: 0, 0.1, 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "train_df, val_df = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Function to create data generators with different augmentation scales\n",
    "def create_data_generators(train_df, val_df, scale):\n",
    "    flip = True\n",
    "    \n",
    "    if scale == 0:\n",
    "        flip = False\n",
    "        \n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0/255,\n",
    "        horizontal_flip=flip,\n",
    "        brightness_range=[1 - scale, 1 + scale],  # Adjust brightness\n",
    "        zoom_range=[1 - scale, 1 + scale],  # Adjust zoom\n",
    "        width_shift_range=scale,  # Adjust width shift\n",
    "        height_shift_range=scale,  # Adjust height shift\n",
    "        shear_range=scale,\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "\n",
    "    val_datagen = ImageDataGenerator(rescale=1.0 / 255, preprocessing_function=preprocess_input)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        train_df,\n",
    "        directory=image_dir,\n",
    "        x_col='id',\n",
    "        y_col='stable_height',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_dataframe(\n",
    "        val_df,\n",
    "        directory=image_dir,\n",
    "        x_col='id',\n",
    "        y_col='stable_height',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator\n",
    "\n",
    "# Define the model using EfficientNetB0\n",
    "def create_model():\n",
    "    # Base model\n",
    "    base_model = EfficientNetB0(include_top=False, weights='imagenet', \n",
    "                                input_shape=(224, 224, 3))\n",
    "    inputs = layers.Input(shape=(224, 224, 3))\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = base_model(inputs)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # Classification layer\n",
    "    regression_output = layers.Dense(6, name='regression_output')(x)\n",
    "    classification_output = layers.Softmax(name='classification_output')(regression_output)\n",
    "\n",
    "    # Compiling the model\n",
    "    model = models.Model(inputs=inputs, outputs=classification_output)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "# Function to train the model with different augmentation scales\n",
    "def train_model_with_scale(scale, epochs=10):\n",
    "    train_generator, val_generator = create_data_generators(train_df, val_df, scale)\n",
    "    smodel = create_model()\n",
    "\n",
    "    # Train the model\n",
    "    history = smodel.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_generator\n",
    "    )\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train the model with different scales\n",
    "scales = [0.0, 0.1, 0.2]  # No augmentation, ±0.1 scale, ±0.2 scale\n",
    "histories = []\n",
    "\n",
    "for scale in scales:\n",
    "    print(f\"\\nTraining with scale: {scale}\")\n",
    "    history = train_model_with_scale(scale)\n",
    "    histories.append(history)\n",
    "\n",
    "# Initialize lists to store best accuracy and loss for each scale\n",
    "best_acc = []\n",
    "best_loss = []\n",
    "\n",
    "# Extract best accuracy and loss from each history\n",
    "for history in histories:\n",
    "    best_acc.append(max(history.history['val_acc']))  # Best validation accuracy\n",
    "    best_loss.append(min(history.history['val_loss']))  # Best validation loss\n",
    "\n",
    "# Create a bar plot for best accuracy\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(np.arange(len(scales)), best_acc, color='skyblue')\n",
    "plt.xticks(np.arange(len(scales)), [f'Scale {s}' for s in scales])\n",
    "plt.title('Best Validation Accuracy by Data Augmentation Scale')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Data Augmentation Scale')\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(np.arange(len(scales)), best_loss, color='lightcoral')\n",
    "plt.xticks(np.arange(len(scales)), [f'Scale {s}' for s in scales])\n",
    "plt.title('Best Validation Loss by Data Augmentation Scale')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Data Augmentation Scale')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with different pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0, ResNet50, VGG16\n",
    "from tensorflow.keras.callbacks import  ModelCheckpoint\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    directory=image_dir,\n",
    "    x_col='id',\n",
    "    y_col='stable_height',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='raw'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    directory=image_dir,\n",
    "    x_col='id',\n",
    "    y_col='stable_height',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='raw'\n",
    ")\n",
    "\n",
    "# Function to create models with different backbones\n",
    "def create_model(base_model):\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(6),  \n",
    "        layers.Softmax()\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "# List of pretrained models to experiment with\n",
    "pretrained_models = {\n",
    "    \"EfficientNetB0\": EfficientNetB0(include_top=False, weights='imagenet', input_shape=(224, 224, 3)),\n",
    "    \"ResNet50\": ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3)),\n",
    "    \"VGG16\": VGG16(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "}\n",
    "\n",
    "# Dictionary to store the results of each model\n",
    "results = {}\n",
    "\n",
    "# Loop over each pretrained model\n",
    "for model_name, base_model in pretrained_models.items():\n",
    "    print(f\"Training model: {model_name}\")\n",
    "\n",
    "    # Create model\n",
    "    model = create_model(base_model)\n",
    "\n",
    "    # Set up model checkpointing\n",
    "    model_checkpoint_path = f'best_model_{model_name}.keras'\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        model_checkpoint_path,\n",
    "        monitor='val_acc',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = 30\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=val_generator,\n",
    "        callbacks=[checkpoint_callback]\n",
    "    )\n",
    "\n",
    "    # Save training history for this model\n",
    "    results[model_name] = history.history\n",
    "\n",
    "# Plot training vs validation accuracy and loss for each model\n",
    "for model_name, history in results.items():\n",
    "    # Create a figure for each model\n",
    "    plt.figure(figsize=(14, 5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history['acc'], label='Training Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "    plt.title(f'{model_name} Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history['loss'], label='Training Loss')\n",
    "    plt.plot(history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'{model_name} Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot for the current model\n",
    "    plt.suptitle(f'Performance of {model_name}', fontsize=16)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])  # Adjust layout to accommodate title\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with different number of fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to create data generators with a fixed augmentation scale\n",
    "def create_data_generators(train_df, val_df):\n",
    "    scale = 0.2  # Fixed scale for augmentation\n",
    "    flip = True\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1.0/255,\n",
    "        horizontal_flip=flip,\n",
    "        brightness_range=[1 - scale, 1 + scale],  # Adjust brightness\n",
    "        zoom_range=[1 - scale, 1 + scale],  # Adjust zoom\n",
    "        width_shift_range=scale,  # Adjust width shift\n",
    "        height_shift_range=scale,  # Adjust height shift\n",
    "        shear_range=scale,\n",
    "        preprocessing_function=preprocess_input\n",
    "    )\n",
    "\n",
    "    val_datagen = ImageDataGenerator(rescale=1.0 / 255, preprocessing_function=preprocess_input)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        train_df,\n",
    "        directory=image_dir,\n",
    "        x_col='id',\n",
    "        y_col='stable_height',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    val_generator = val_datagen.flow_from_dataframe(\n",
    "        val_df,\n",
    "        directory=image_dir,\n",
    "        x_col='id',\n",
    "        y_col='stable_height',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='raw',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator\n",
    "\n",
    "# Define the model using EfficientNetB0 with decreasing number of dense layers\n",
    "def create_model(num_dense_layers):\n",
    "    base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "    inputs = layers.Input(shape=(224, 224, 3))\n",
    "    x = base_model(inputs)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Define sizes for the dense layers, decreasing from 512\n",
    "    layer_sizes = [512, 256, 128, 64]  # Adjust sizes as needed\n",
    "    \n",
    "    for i in range(num_dense_layers):\n",
    "        x = layers.Dense(layer_sizes[i], activation='relu')(x)\n",
    "        x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    regression_output = layers.Dense(6, name='regression_output')(x)\n",
    "    classification_output = layers.Softmax(name='classification_output')(regression_output)\n",
    "    model = models.Model(inputs=inputs, outputs=classification_output)\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "# Function to train the model with K-Fold cross-validation\n",
    "def cross_validate_model(num_dense_layers, k=5, epochs=10):\n",
    "    kf = KFold(n_splits=k)\n",
    "    best_accs = []\n",
    "    best_losses = []\n",
    "\n",
    "    print(f\"\\nCross-Validating with {num_dense_layers} dense layers\")\n",
    "    \n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(data)):\n",
    "        print(f\"\\nFold {fold + 1}/{k}\")\n",
    "        train_df = data.iloc[train_index]\n",
    "        val_df = data.iloc[val_index]\n",
    "\n",
    "        train_generator, val_generator = create_data_generators(train_df, val_df)\n",
    "        model = create_model(num_dense_layers)\n",
    "\n",
    "        # Train the model and track the best accuracy and loss\n",
    "        history = model.fit(\n",
    "            train_generator,\n",
    "            epochs=epochs,\n",
    "            validation_data=val_generator,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Track only the best validation accuracy and loss for this fold\n",
    "        best_acc = max(history.history['val_acc'])\n",
    "        best_loss = min(history.history['val_loss'])\n",
    "\n",
    "        best_accs.append(best_acc)\n",
    "        best_losses.append(best_loss)\n",
    "\n",
    "    return best_accs, best_losses\n",
    "\n",
    "# Test different configurations of dense layers\n",
    "num_layers_options = [1, 2, 3, 4]  # Varying number of dense layers\n",
    "avg_best_acc = []\n",
    "avg_best_loss = []\n",
    "\n",
    "# Cross-validate over different layer configurations\n",
    "for num_layers in num_layers_options:\n",
    "    best_accs, best_losses = cross_validate_model(num_layers)\n",
    "    avg_best_acc.append(np.mean(best_accs))  # Average best accuracy across folds\n",
    "    avg_best_loss.append(np.mean(best_losses))  # Average best loss across folds\n",
    "\n",
    "# Create a line plot for average accuracy and loss\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.arange(len(num_layers_options)), avg_best_acc, marker='o', linestyle='-', color='skyblue')\n",
    "plt.xticks(np.arange(len(num_layers_options)), [f'{num_layers} Layers' for num_layers in num_layers_options])\n",
    "plt.title('Average Best Validation Accuracy by Dense Layers (Fixed Scale 0.2)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Dense Layers')\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(np.arange(len(num_layers_options)), avg_best_loss, marker='o', linestyle='-', color='lightcoral')\n",
    "plt.xticks(np.arange(len(num_layers_options)), [f'{num_layers} Layers' for num_layers in num_layers_options])\n",
    "plt.title('Average Best Validation Loss by Dense Layers (Fixed Scale 0.2)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Number of Dense Layers')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our finding, we define our final model as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4196851198.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Based on\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1.0/255,  # Normalize pixel values to [0, 1]\n",
    "    horizontal_flip = True,  # Randomly flip images horizontally\n",
    "    brightness_range = [0.8, 1.2],  # Adjust brightness by a random factor\n",
    "    zoom_range = [0.8, 1.2],  # Randomly zoom into images\n",
    "    width_shift_range = 0.2,  # Randomly shift images horizontally (10% of total width)\n",
    "    height_shift_range = 0.2,  # Randomly shift images vertically (10% of total height)\n",
    "    shear_range = 0.2,  # Apply random shear transformations\n",
    "    preprocessing_function=preprocess_input  # Normalize using ImageNet mean and std\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255,\n",
    "                                preprocessing_function=preprocess_input)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    directory=image_dir,\n",
    "    x_col='id',\n",
    "    y_col='stable_height',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='raw',  # For regression, use 'raw'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    directory=image_dir,\n",
    "    x_col='id',\n",
    "    y_col='stable_height',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='raw',  # For regression, use 'raw'\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Define the model using EfficientNetB0\n",
    "def create_model():\n",
    "    base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "\n",
    "    # Input layer\n",
    "    inputs = layers.Input(shape=(224, 224, 3))\n",
    "\n",
    "    # EfficientNetB0 as the base model\n",
    "    base_model = EfficientNetB0(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "\n",
    "    # Add layers to the model\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)  # Global average pooling\n",
    "    x = layers.Dense(512, activation='relu')(x)              # Dense layer with ReLU\n",
    "    x = layers.Dropout(0.3)(x)                               # Dropout layer\n",
    "    x = layers.Dense(256, activation='relu')(x)              # Dense layer with ReLU\n",
    "    x = layers.Dropout(0.3)(x)                               # Dropout layer\n",
    "    x = layers.Dense(128, activation='relu')(x)              # Dense layer with ReLU\n",
    "    x = layers.Dropout(0.3)(x)                               # Dropout layer\n",
    "\n",
    "    # Outputs\n",
    "    regression_output = layers.Dense(6, name='regression_output')(x)  \n",
    "    classification_output = layers.Softmax(name='classification_output')(regression_output) \n",
    "\n",
    "    # Create the model\n",
    "    model = keras.models.Model(inputs=inputs, outputs= classification_output)\n",
    "\n",
    "\n",
    "    # Adjust optimizer and loss function for mixed precision\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['acc']) \n",
    "    return model\n",
    "\n",
    "# Create and train the model\n",
    "model = create_model()\n",
    "\n",
    "# Set the filepath to save the best model\n",
    "model_checkpoint_path = 'best_model.keras' \n",
    "\n",
    "# Set up ModelCheckpoint callback\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    model_checkpoint_path,\n",
    "    monitor='val_acc',\n",
    "    save_best_only=True, \n",
    "    mode='max', \n",
    "    verbose=1  \n",
    ")\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 30\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting predictions in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model = load_model('best_model.keras')\n",
    "# # Load the previously saved model\n",
    "\n",
    "# # Load the test CSV file\n",
    "test_csv_path = f'{syspath}stack-stability-prediction/src/data/test/test.csv'\n",
    "test_data = pd.read_csv(test_csv_path)\n",
    "test_data['img_id'] = test_data['id'].astype(str) + '.jpg'\n",
    "# Set the directory for the test images\n",
    "test_image_dir = f'{syspath}stack-stability-prediction/src/data/test/test' \n",
    "\n",
    "# Create a data generator for test images\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "# Create a generator for the test data\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    test_data,\n",
    "    directory=test_image_dir,\n",
    "    x_col='img_id',\n",
    "    y_col=None, \n",
    "    target_size=(224, 224),  # Adjust to match input size of the model\n",
    "    batch_size=32,\n",
    "    class_mode=None, \n",
    "    shuffle=False  # Don't shuffle the test data\n",
    ")\n",
    "\n",
    "\n",
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = predictions.argmax(axis=1) + 1  # For classification\n",
    "\n",
    "# Create a DataFrame with predictions\n",
    "results = pd.DataFrame({\n",
    "    'id': test_data['id'],  # Image IDs\n",
    "    'predicted_stable_height': predicted_classes  # Predictions\n",
    "})\n",
    "\n",
    "# Save predictions to a CSV file\n",
    "results.to_csv('predictions.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acquiring the final model's prediction on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model_path = \"best_model.keras\"\n",
    "\n",
    "best_model = load_model(best_model_path)\n",
    "\n",
    "# Get predictions\n",
    "val_predictions = best_model.predict(val_generator)\n",
    "\n",
    "# \n",
    "predicted_classes = val_predictions.argmax(axis=1)  # For classification\n",
    "val_preds = pd.DataFrame({\"id\": val_df['id'], \"true\":val_df['stable_height'], \"pred\":predicted_classes})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the proportion of error in each height against class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate errors (1 for incorrect prediction, 0 for correct)\n",
    "val_preds['error'] = (val_preds['true'] != val_preds['pred']).astype(int)\n",
    "\n",
    "# Group by the true height class and calculate the proportion of errors\n",
    "error_by_height = val_preds.groupby('true')['error'].mean()\n",
    "\n",
    "# Calculate the distribution of true heights (i.e., count of each height class)\n",
    "height_distribution = val_preds['true'].value_counts().sort_index()\n",
    "\n",
    "# Create subplots: 2 plots side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot 1: Error rate for each height class\n",
    "axes[0].bar(error_by_height.index, error_by_height.values, color='salmon')\n",
    "axes[0].set_title('Proportion of Prediction Errors by Height Class')\n",
    "axes[0].set_xlabel('True Height Class')\n",
    "axes[0].set_ylabel('Error Rate')\n",
    "axes[0].set_xticks(error_by_height.index)\n",
    "\n",
    "# Plot 2: Distribution of true height classes\n",
    "axes[1].bar(height_distribution.index, height_distribution.values, color='skyblue')\n",
    "axes[1].set_title('Height Class Distribution')\n",
    "axes[1].set_xlabel('Height Class')\n",
    "axes[1].set_ylabel('Number of Samples')\n",
    "axes[1].set_xticks(height_distribution.index)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "cm = confusion_matrix(val_df['stable_height'], predicted_classes)\n",
    "\n",
    "# Define class labels (in this case, 1 to 6)\n",
    "class_labels = np.arange(1, 7)\n",
    "\n",
    "# Create the heatmap with the appropriate class labels\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the precision and recall for each stable height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    TP = cm[i, i]\n",
    "    FP = cm[:, i].sum() - TP\n",
    "    FN = cm[i, :].sum() - TP\n",
    "    Precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    Recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    F1 = 2 * (Precision * Recall) / (Precision + Recall) if (Precision + Recall) > 0 else 0\n",
    "    \n",
    "    print(f'Class {i}: Precision={Precision:.2f}, Recall={Recall:.2f}, F1 Score={F1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code is used to create Grad-CAM map on 12 misclassified images. The functions have been adapted from the week 5 workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import matplotlib.cm as cm\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, pred_index=None):\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    \n",
    "    grad_model = keras.models.Model(\n",
    "        model.inputs, [model.get_layer(\"top_conv\").output, model.get_layer(\"regression_output\").output]\n",
    "    )\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen)\n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    # then sum all the channels to obtain the heatmap class activation\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def display_gradcam(img_name, heatmap, alpha=0.4):\n",
    "\n",
    "    # Load the original image\n",
    "    img = image.load_img(img_name)\n",
    "    img = image.img_to_array(img)\n",
    "\n",
    "    # Rescale heatmap to a range 0-255\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "\n",
    "    # Use jet colormap to colorize heatmap\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "\n",
    "    # Use RGB values of the colormap\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # Create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * alpha + img\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "\n",
    "    # Display superimpose result\n",
    "    plt.matshow(superimposed_img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "inc = 0\n",
    "\n",
    "for i in range(val_preds.shape[0]):\n",
    "    if inc == 12:\n",
    "        break\n",
    "    \n",
    "    if val_preds.iloc[i]['true'] != val_preds.iloc[i]['pred']:\n",
    "        inc += 1\n",
    "        img_id = val_preds.iloc[i]['id']\n",
    "\n",
    "        # Load and preprocess your image\n",
    "        img = keras.utils.load_img(image_dir+img_id)  # Path to your image\n",
    "        img = keras.utils.img_to_array(img)\n",
    "        # Normalize to [0, 1]\n",
    "        img = img / 255.0  # Scale pixel values to [0, 1]\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "\n",
    "\n",
    "        preds = model.predict(img)\n",
    "        print(\"Image: \", val_preds.iloc[i]['id'])\n",
    "        print(\"Predicted:\", val_preds.iloc[i]['pred'] + 1)\n",
    "        print(\"Correct:\", val_preds.iloc[i]['true'] + 1)\n",
    "        heatmap = make_gradcam_heatmap(img, model)\n",
    "\n",
    "        display_gradcam(image_dir+img_id, heatmap)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling image loading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms, models\n",
    "from torchvision.transforms import RandomAffine, ColorJitter, RandomHorizontalFlip\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from torchvision.models import ResNet18_Weights\n",
    "import cv2\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import efficientnet_b4, EfficientNet_B4_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BlockStackDataset class for handling image loading and preprocessing\n",
    "class BlockStackDataset(Dataset):\n",
    "    def __init__(self, data_file, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Initializes the dataset with the data file (pandas DataFrame), image directory, \n",
    "        and optional transformations.\n",
    "        \n",
    "        Args:\n",
    "        - data_file: A pandas DataFrame containing image information and labels.\n",
    "        - img_dir: Path to the directory containing the images.\n",
    "        - transform: Optional transformations to be applied to the images (e.g., resizing).\n",
    "        \"\"\"\n",
    "        self.data_file = data_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the total number of samples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.data_file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieves an image, label, and instability type based on the given index.\n",
    "        \n",
    "        Args:\n",
    "        - idx: Index of the item in the dataset to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "        - image: The processed image.\n",
    "        - label: The stable height label.\n",
    "        - instability_type: The instability type.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Construct the image file path\n",
    "            img_name = self.img_dir + '/' + str(self.data_file.iloc[idx, 0]) + '.jpg'\n",
    "            image = Image.open(img_name).convert('RGB')\n",
    "            \n",
    "            # Retrieve the label from the DataFrame\n",
    "            label = self.data_file.iloc[idx, 6] - 1\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            return image, label\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image at index {idx}: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class for handling test data\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        # Initialize by loading the csv file and setting image directory and transformations\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of data entries (images)\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Fetch the image filename based on the index\n",
    "        img_name = self.img_dir + '/' + str(self.data.iloc[idx, 0]) + '.jpg'\n",
    "        image = Image.open(img_name).convert('RGB') # Open and convert image to RGB\n",
    "\n",
    "        # Apply transformations if any are defined\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # Return image and its corresponding ID from the csv file\n",
    "        return image, self.data.iloc[idx, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to define and return data augmentation and preprocessing transformations\n",
    "def Data_Augumentation():\n",
    "    # Training transformations: resizing, flipping, color jitter, affine transformation, normalization\n",
    "    train_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.RandomAffine(degrees=0, translate=(0.1,0.1)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    # Validation transformations: resizing and normalization\n",
    "    val_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    # Test transformations: resizing and normalization\n",
    "    test_transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    return train_transform, val_transform, test_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a directory for logging and saving model data\n",
    "def create_log_dir():\n",
    "     # Get current time to create a unique directory for model training logs and results\n",
    "    current_time = datetime.now().strftime('%y-%m-%d_%H-%M-%S')\n",
    "    best_solution_dir = f'model_trained/experiment_{current_time}'\n",
    "\n",
    "    # Create the directory if it does not exist\n",
    "    os.makedirs(best_solution_dir, exist_ok=True)\n",
    "    \n",
    "    # Return the directory path\n",
    "    return best_solution_dir\n",
    "    \n",
    "# Function to save model state and log training details\n",
    "def save_model_and_log(model, optimizer, epoch, train_loss, val_accuracy, best_val_accuracy, log_dir):\n",
    "    # Check if the current validation accuracy is the best\n",
    "    is_best = val_accuracy > best_val_accuracy\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'best_val_accuracy': best_val_accuracy,\n",
    "    }\n",
    "    \n",
    "    torch.save(checkpoint, os.path.join(log_dir, 'last_model.pth'))\n",
    "    \n",
    "    # If the current model is the best, save it separately\n",
    "    if is_best:\n",
    "        torch.save(checkpoint, os.path.join(log_dir, 'best_model.pth'))\n",
    "        print(f\"New best model saved with accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "    # Log the training data to a text file\n",
    "    log_data = f\"Epoch: {epoch}, Train Loss: {train_loss}, Val Accuracy: {val_accuracy}, Best Val Accuracy: {best_val_accuracy}\\n\"\n",
    "    \n",
    "    with open(os.path.join(log_dir, 'training_log.txt'), 'a') as f:\n",
    "        f.write(log_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop function\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    best_solution_dir = create_log_dir()\n",
    "    \n",
    "    print(\"Trainning Model...\")\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "    \n",
    "    # Lists to store loss and accuracy values over epochs\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    # Loop through each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Set the model to training mode\n",
    "        train_loss = 0.0\n",
    "        train_accuracy = 0.0\n",
    "        \n",
    "        # Visualize progress using tqdm\n",
    "        with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "            tepoch.set_description(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "            # Loop through batches of training data\n",
    "            for inputs, labels in tepoch:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Reset gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                raw_outputs = model(inputs)\n",
    "                loss = criterion(raw_outputs, labels)            \n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Update loss and accuracy for the epoch\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = torch.max(raw_outputs.data, 1)\n",
    "                accuracy = (predicted == labels).sum().item() / labels.size(0)\n",
    "                train_accuracy += accuracy\n",
    "\n",
    "                # Display progress in tqdm\n",
    "                tepoch.set_postfix(loss=train_loss / len(train_loader), accuracy=train_accuracy / len(train_loader))\n",
    "\n",
    "            # Compute average loss and accuracy for the epoch\n",
    "            epoch_loss = train_loss / len(train_loader)\n",
    "            epoch_accuracy = train_accuracy / len(train_loader)\n",
    "            train_losses.append(epoch_loss)\n",
    "            train_accuracies.append(epoch_accuracy)\n",
    "        \n",
    "        # Validation phase\n",
    "        print(\"Validating...\")\n",
    "        \n",
    "        model.eval() # Set model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs) # Forward pass\n",
    "                # predicted = torch.argmax(outputs, 1)\n",
    "\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Calculate average validation accuracy\n",
    "            val_accuracy = correct / total\n",
    "            val_loss = val_loss / len(val_loader)\n",
    "            val_losses.append(val_loss)\n",
    "            val_accuracies.append(val_accuracy)\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # Save the best model based on validation accuracy\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), f'{best_solution_dir}/best_model.pth')\n",
    "        print(f\"Best accuracy so far: {best_val_accuracy:.4f}\")\n",
    "\n",
    "        # Save model and log details\n",
    "        save_model_and_log(model, optimizer, epoch, train_losses, val_accuracy, best_val_accuracy, best_solution_dir)\n",
    "    \n",
    "    # Return final model and performance metrics\n",
    "    return model, best_val_accuracy, train_accuracies, val_accuracies, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "train_image_folder = f'{syspath}stack-stability-prediction/src/data/train/train'\n",
    "test_image_folder = f'{syspath}stack-stability-prediction/src/data/test/test'\n",
    "\n",
    "train_csv_path = f'{syspath}stack-stability-prediction/src/data/train/train.csv'\n",
    "test_csv_path = f'{syspath}stack-stability-prediction/src/data/test/test.csv'\n",
    "\n",
    "batch_size=16\n",
    "learning_rate=0.001\n",
    "\n",
    "# Data preparation and augumentation\n",
    "train_transform, val_transform, test_transform = Data_Augumentation()\n",
    "\n",
    "full_data = pd.read_csv(train_csv_path)\n",
    "\n",
    "train_data, val_data = train_test_split(full_data, test_size=0.1, random_state=42, shuffle=False)\n",
    "train_data = pd.concat([train_data]*5, ignore_index=True)\n",
    "\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Validation data shape:\", val_data.shape)\n",
    "    \n",
    "# Create datasets with appropriate transforms\n",
    "train_dataset = BlockStackDataset(train_data, train_image_folder, transform=train_transform)\n",
    "val_dataset = BlockStackDataset(val_data, train_image_folder, transform=val_transform)\n",
    "    \n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "test_dataset = TestDataset(test_csv_path, test_image_folder, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockStackDataset_imagePro(Dataset):\n",
    "    def __init__(self, data_file, img_dir, transform=None):\n",
    "        self.data_file = data_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_file)\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        # Convert the image to HSV for better color segmentation\n",
    "        hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # Define color ranges for all the block colors (adjust the values as needed)\n",
    "        lower_blue = np.array([100, 150, 50])\n",
    "        upper_blue = np.array([140, 255, 255])\n",
    "\n",
    "        lower_red1 = np.array([0, 150, 50])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([170, 150, 50])\n",
    "        upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "        lower_green = np.array([40, 50, 50])\n",
    "        upper_green = np.array([80, 255, 255])\n",
    "\n",
    "        lower_yellow = np.array([20, 100, 100])\n",
    "        upper_yellow = np.array([30, 255, 255])\n",
    "\n",
    "        lower_cyan = np.array([85, 150, 50])\n",
    "        upper_cyan = np.array([95, 255, 255])\n",
    "\n",
    "        lower_magenta = np.array([145, 150, 50])\n",
    "        upper_magenta = np.array([155, 255, 255])\n",
    "\n",
    "        # Create masks for each block color\n",
    "        mask_blue = cv2.inRange(hsv_image, lower_blue, upper_blue)\n",
    "        mask_red1 = cv2.inRange(hsv_image, lower_red1, upper_red1)\n",
    "        mask_red2 = cv2.inRange(hsv_image, lower_red2, upper_red2)\n",
    "        mask_red = mask_red1 | mask_red2  # Combine the two red masks\n",
    "        mask_green = cv2.inRange(hsv_image, lower_green, upper_green)\n",
    "        mask_yellow = cv2.inRange(hsv_image, lower_yellow, upper_yellow)\n",
    "        mask_cyan = cv2.inRange(hsv_image, lower_cyan, upper_cyan)\n",
    "        mask_magenta = cv2.inRange(hsv_image, lower_magenta, upper_magenta)\n",
    "\n",
    "        # Combine all masks to get the entire stack\n",
    "        combined_mask = mask_blue | mask_red | mask_green | mask_yellow | mask_cyan | mask_magenta\n",
    "\n",
    "        # Use the combined mask to extract the entire stack from the original image\n",
    "        result_stack = cv2.bitwise_and(image, image, mask=combined_mask)\n",
    "\n",
    "        return result_stack\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_dir + '/' + str(self.data_file.iloc[idx, 0]) + '.jpg'\n",
    "        \n",
    "        # Read image using OpenCV\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        # Apply preprocessing\n",
    "        processed_image = self.preprocess_image(image)\n",
    "        \n",
    "        # Convert to PIL Image for PyTorch transforms\n",
    "        processed_image = Image.fromarray(cv2.cvtColor(processed_image, cv2.COLOR_BGR2RGB))\n",
    "        \n",
    "        label = self.data_file.iloc[idx, 6] - 1\n",
    "        \n",
    "        if self.transform:\n",
    "            processed_image = self.transform(processed_image)\n",
    "        \n",
    "        return processed_image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ResNet18 Model\n",
    "        \n",
    "print(\"Setting Model...\")\n",
    "        \n",
    "# Load pre-trained ResNet18 and remove the last fully connected layer\n",
    "model_resnet18 = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_resnet18.fc.in_features\n",
    "model_resnet18.fc = nn.Linear(num_ftrs, 6)\n",
    "\n",
    "# Define a custom fully connected layer for your specific task\n",
    "# model_resnet18.fc = nn.Sequential(\n",
    "#         nn.Linear(num_ftrs, 512),    # Adjust 512 according to your needs\n",
    "#         nn.ReLU(),\n",
    "#        nn.Dropout(0.5),\n",
    "#        nn.Linear(512, 1)            # Output layer for regression (predicting stable height)\n",
    "# )\n",
    "  \n",
    "# Model, loss, and optimizer\n",
    "model_resnet18 = model_resnet18.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_resnet18.parameters(), lr=learning_rate)\n",
    "\n",
    "for param in model_resnet18.parameters():\n",
    "    param.requires_grad = True \n",
    "\n",
    "resnet18, best_accuracy, train_accuracies, val_accuracies, train_losses, val_losses = train_model(model_resnet18, criterion, optimizer, train_loader, val_loader, num_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet18 - image processing by removing background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets with appropriate transforms\n",
    "train_dataset_imgP = BlockStackDataset_imagePro(train_data, train_image_folder, transform=train_transform)\n",
    "val_dataset_imgP = BlockStackDataset_imagePro(val_data, train_image_folder, transform=val_transform)\n",
    "    \n",
    "# Create data loaders\n",
    "train_loader_imgP = DataLoader(train_dataset_imgP, batch_size=batch_size, shuffle=True)\n",
    "val_loader_imgP = DataLoader(val_dataset_imgP, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load ResNet18 Model\n",
    "        \n",
    "print(\"Setting Model...\")\n",
    "        \n",
    "# Load pre-trained ResNet18 and remove the last fully connected layer\n",
    "model_resnet18 = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = model_resnet18.fc.in_features\n",
    "model_resnet18.fc = nn.Linear(num_ftrs, 6)\n",
    "\n",
    "model_resnet18 = model_resnet18.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model_resnet18.parameters(), lr=learning_rate)\n",
    "\n",
    "for param in model_resnet18.parameters():\n",
    "    param.requires_grad = True \n",
    "\n",
    "resnet18_imgP, best_accuracy, train_accuracies, val_accuracies = train_model(model_resnet18, criterion, optimizer, train_loader_imgP, val_loader_imgP, num_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnext101_32x8d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition using resnext101_32x8d pre-trained on ImageNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNeXt101_32X8D_Weights\n",
    "\n",
    "model_resnext101 = models.resnext101_32x8d(weights=models.ResNeXt101_32X8D_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Get the number of input features to the FC layer\n",
    "num_ftrs = model_resnext101.fc.in_features\n",
    "model_resnext101.fc = nn.Linear(num_ftrs, 6)\n",
    "\n",
    "# Model, loss, and optimizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_resnext101 = model_resnext101.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_resnext101.parameters(), lr=learning_rate)\n",
    "\n",
    "# Fine-tuning: Unfreeze all the layers\n",
    "for param in model_resnext101.parameters():\n",
    "    param.requires_grad = True  # Unfreeze all layers for fine-tuning\n",
    "\n",
    "model_resnext101, best_accuracy, train_accuracies, val_accuracies = train_model(model_resnext101, criterion, optimizer, train_loader, val_loader, num_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnext101_32x8d - image processing by removing background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition using resnext101_32x8d pre-trained on ImageNet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models import ResNeXt101_32X8D_Weights\n",
    "\n",
    "model_resnext101 = models.resnext101_32x8d(weights=models.ResNeXt101_32X8D_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Get the number of input features to the FC layer\n",
    "num_ftrs = model_resnext101.fc.in_features\n",
    "model_resnext101.fc = nn.Linear(num_ftrs, 6)\n",
    "\n",
    "# Model, loss, and optimizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_resnext101 = model_resnext101.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_resnext101.parameters(), lr=learning_rate)\n",
    "\n",
    "# Fine-tuning: Unfreeze all the layers\n",
    "for param in model_resnext101.parameters():\n",
    "    param.requires_grad = True  # Unfreeze all layers for fine-tuning\n",
    "\n",
    "model_resnext101, best_accuracy, train_accuracies, val_accuracies = train_model(model_resnext101, criterion, optimizer, train_loader_imgP, val_loader_imgP, num_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet-B4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition using EfficientNetB4 pre-trained on ImageNet\n",
    "model_efficientnetb4 = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = model_efficientnetb4.classifier[1].in_features\n",
    "model_efficientnetb4.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(128, 6)  # Changed to 6 output neurons for 6 classes\n",
    ")\n",
    "\n",
    "model_efficientnetb4 = model_efficientnetb4.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Changed to CrossEntropyLoss for classification\n",
    "optimizer = optim.Adam(model_efficientnetb4.parameters(), lr=learning_rate)\n",
    "\n",
    "# Fine-tuning: Unfreeze all the layers\n",
    "for param in model_efficientnetb4.parameters():\n",
    "    param.requires_grad = True  # Unfreeze all layers for fine-tuning\n",
    "\n",
    "# Training\n",
    "model_efficientnetb4, best_accuracy, train_accuracies, val_accuracies = train_model(\n",
    "    model_efficientnetb4, criterion, optimizer, train_loader, val_loader, num_epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EfficientNet-B4 - image processing by removing background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition using EfficientNetB4 pre-trained on ImageNet\n",
    "model_efficientnetb4 = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\n",
    "num_ftrs = model_efficientnetb4.classifier[1].in_features\n",
    "model_efficientnetb4.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(128, 6)  # Changed to 6 output neurons for 6 classes\n",
    ")\n",
    "\n",
    "model_efficientnetb4 = model_efficientnetb4.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # Changed to CrossEntropyLoss for classification\n",
    "optimizer = optim.Adam(model_efficientnetb4.parameters(), lr=learning_rate)\n",
    "\n",
    "# Fine-tuning: Unfreeze all the layers\n",
    "for param in model_efficientnetb4.parameters():\n",
    "    param.requires_grad = True  # Unfreeze all layers for fine-tuning\n",
    "\n",
    "# Training\n",
    "model_efficientnetb4, best_accuracy, train_accuracies, val_accuracies = train_model(\n",
    "    model_efficientnetb4, criterion, optimizer, train_loader_imgP, val_loader_imgP, num_epochs = 10)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9536705,
     "sourceId": 57032,
     "sourceType": "competition"
    },
    {
     "datasetId": 5825359,
     "sourceId": 9559601,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
